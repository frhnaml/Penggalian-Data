{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Handling Categorical Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First few rows of the dataset:\n",
      "   age         job  marital  education default  balance housing loan  contact  \\\n",
      "0   59      admin.  married  secondary      no     2343     yes   no  unknown   \n",
      "1   56      admin.  married  secondary      no       45      no   no  unknown   \n",
      "2   41  technician  married  secondary      no     1270     yes   no  unknown   \n",
      "3   55    services  married  secondary      no     2476     yes   no  unknown   \n",
      "4   54      admin.  married   tertiary      no      184      no   no  unknown   \n",
      "\n",
      "   day month  duration  campaign  pdays  previous poutcome deposit  \n",
      "0    5   may      1042         1     -1         0  unknown     yes  \n",
      "1    5   may      1467         1     -1         0  unknown     yes  \n",
      "2    5   may      1389         1     -1         0  unknown     yes  \n",
      "3    5   may       579         1     -1         0  unknown     yes  \n",
      "4    5   may       673         2     -1         0  unknown     yes  \n",
      "Categorical columns: Index(['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact',\n",
      "       'month', 'poutcome', 'deposit'],\n",
      "      dtype='object')\n",
      "Displaying the modified dataset with relevant columns:\n",
      "   education  education_encoded  marital  marital_encoded  age  age_binned\n",
      "0  secondary                  1  married              1.0   59  Paruh Baya\n",
      "1  secondary                  1  married              1.0   56  Paruh Baya\n",
      "2  secondary                  1  married              1.0   41  Paruh Baya\n",
      "3  secondary                  1  married              1.0   55  Paruh Baya\n",
      "4   tertiary                  2  married              1.0   54  Paruh Baya\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, OrdinalEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"tugas3_genap.csv\")\n",
    "\n",
    "# Display the first few rows to inspect the data\n",
    "print(\"First few rows of the dataset:\")\n",
    "print(df.head())\n",
    "\n",
    "# Identify categorical columns\n",
    "categorical_columns = df.select_dtypes(include=['object']).columns\n",
    "print(f\"Categorical columns: {categorical_columns}\")\n",
    "\n",
    "# Check if required columns exist\n",
    "required_columns = ['education', 'job', 'marital', 'age']\n",
    "missing_columns = [col for col in required_columns if col not in df.columns]\n",
    "if missing_columns:\n",
    "    print(f\"Warning: The following required columns are missing: {missing_columns}\")\n",
    "\n",
    "# Apply different encoding methods to 3 columns:\n",
    "\n",
    "# 1. Label Encoding on one column (example: 'education')\n",
    "if 'education' in df.columns:\n",
    "    label_encoder = LabelEncoder()\n",
    "    df['education_encoded'] = label_encoder.fit_transform(df['education'])\n",
    "\n",
    "# 2. One-Hot Encoding on 'job' (if the column exists)\n",
    "if 'job' in df.columns:\n",
    "    df = pd.get_dummies(df, columns=['job'], drop_first=True)\n",
    "\n",
    "# 3. Ordinal Encoding on 'marital' (if the column exists)\n",
    "if 'marital' in df.columns:\n",
    "    ordinal_encoder = OrdinalEncoder(categories=[['single', 'married', 'divorced']])\n",
    "    df['marital_encoded'] = ordinal_encoder.fit_transform(df[['marital']])\n",
    "\n",
    "# Binning the 'age' column into 4 groups if it exists\n",
    "if 'age' in df.columns:\n",
    "    bins = [0, 25, 40, 60, 100]\n",
    "    labels = ['Muda', 'Dewasa', 'Paruh Baya', 'Lanjut Usia']\n",
    "    df['age_binned'] = pd.cut(df['age'], bins=bins, labels=labels)\n",
    "\n",
    "# View the changes - we will display only relevant columns that were modified or newly created\n",
    "columns_to_display = ['education', 'education_encoded', 'job', 'marital', 'marital_encoded', 'age', 'age_binned']\n",
    "# Check if these columns exist in the dataframe before attempting to display them\n",
    "existing_columns = [col for col in columns_to_display if col in df.columns]\n",
    "print(\"Displaying the modified dataset with relevant columns:\")\n",
    "print(df[existing_columns].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>balance</th>\n",
       "      <th>balance_scaled</th>\n",
       "      <th>duration</th>\n",
       "      <th>duration_scaled</th>\n",
       "      <th>campaign</th>\n",
       "      <th>campaign_scaled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2343</td>\n",
       "      <td>0.104371</td>\n",
       "      <td>1042</td>\n",
       "      <td>1.930226</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>45</td>\n",
       "      <td>0.078273</td>\n",
       "      <td>1467</td>\n",
       "      <td>3.154612</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1270</td>\n",
       "      <td>0.092185</td>\n",
       "      <td>1389</td>\n",
       "      <td>2.929901</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2476</td>\n",
       "      <td>0.105882</td>\n",
       "      <td>579</td>\n",
       "      <td>0.596366</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>184</td>\n",
       "      <td>0.079851</td>\n",
       "      <td>673</td>\n",
       "      <td>0.867171</td>\n",
       "      <td>2</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   balance  balance_scaled  duration  duration_scaled  campaign  \\\n",
       "0     2343        0.104371      1042         1.930226         1   \n",
       "1       45        0.078273      1467         3.154612         1   \n",
       "2     1270        0.092185      1389         2.929901         1   \n",
       "3     2476        0.105882       579         0.596366         1   \n",
       "4      184        0.079851       673         0.867171         2   \n",
       "\n",
       "   campaign_scaled  \n",
       "0             0.01  \n",
       "1             0.01  \n",
       "2             0.01  \n",
       "3             0.01  \n",
       "4             0.02  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "# Min-Max Scaling on 'balance' column\n",
    "scaler_min_max = MinMaxScaler()\n",
    "df['balance_scaled'] = scaler_min_max.fit_transform(df[['balance']])\n",
    "\n",
    "# Z-Score scaling on 'duration' column\n",
    "scaler_zscore = StandardScaler()\n",
    "df['duration_scaled'] = scaler_zscore.fit_transform(df[['duration']])\n",
    "\n",
    "# Decimal scaling on 'campaign' column\n",
    "df['campaign_scaled'] = df['campaign'] / (10 ** np.ceil(np.log10(df['campaign'].max())))\n",
    "\n",
    "# View the changes\n",
    "df[['balance', 'balance_scaled', 'duration', 'duration_scaled', 'campaign', 'campaign_scaled']].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in the dataset: Index(['age', 'marital', 'education', 'default', 'balance', 'housing', 'loan',\n",
      "       'contact', 'day', 'month', 'duration', 'campaign', 'pdays', 'previous',\n",
      "       'poutcome', 'deposit', 'education_encoded', 'job_blue-collar',\n",
      "       'job_entrepreneur', 'job_housemaid', 'job_management', 'job_retired',\n",
      "       'job_self-employed', 'job_services', 'job_student', 'job_technician',\n",
      "       'job_unemployed', 'job_unknown', 'marital_encoded', 'age_binned',\n",
      "       'balance_scaled', 'duration_scaled', 'campaign_scaled',\n",
      "       'deposit_encoded'],\n",
      "      dtype='object')\n",
      "Features highly correlated with target: ['deposit_encoded', 'duration', 'duration_scaled']\n",
      "Number of features selected: 3\n",
      "Selected fewer than 5 features. Manually adding features to reach 5.\n",
      "           PC1          PC2        PC3       PC4           PC5\n",
      "0   816.103135   668.016072  17.483816  0.063236 -1.054268e-12\n",
      "1 -1480.852807  1098.630504  15.471225 -0.184509 -2.023937e-12\n",
      "2  -256.053339  1017.639094  -0.043332 -0.129750 -1.775691e-12\n",
      "3   947.969988   204.691049  13.391875  0.366367 -8.570922e-14\n",
      "4 -1343.793754   304.290346  13.350520  0.330725 -3.783640e-13\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Assuming df is already loaded\n",
    "\n",
    "# Check the columns in the dataset\n",
    "print(\"Columns in the dataset:\", df.columns)\n",
    "\n",
    "# Encode the target column 'deposit' to numeric values\n",
    "label_encoder = LabelEncoder()\n",
    "df['deposit_encoded'] = label_encoder.fit_transform(df['deposit'])\n",
    "\n",
    "# Remove non-numeric columns (e.g., categorical columns like 'marital', 'job', etc.)\n",
    "df_numeric = df.select_dtypes(include=['float64', 'int64'])\n",
    "\n",
    "# Feature Selection based on correlation with the target (now 'deposit_encoded')\n",
    "correlation_matrix = df_numeric.corr()\n",
    "target_corr = correlation_matrix['deposit_encoded'].abs().sort_values(ascending=False)\n",
    "\n",
    "# Lowering the correlation threshold to select more features\n",
    "high_corr_features = target_corr[target_corr > 0.2].index.tolist()  # Adjusted to 0.2 to select more features\n",
    "\n",
    "# Print selected features\n",
    "print(f\"Features highly correlated with target: {high_corr_features}\")\n",
    "\n",
    "# Check how many features were selected\n",
    "print(f\"Number of features selected: {len(high_corr_features)}\")\n",
    "\n",
    "# Ensure at least 5 features are selected, otherwise, adjust the threshold or manually add more features\n",
    "if len(high_corr_features) < 5:\n",
    "    print(\"Selected fewer than 5 features. Manually adding features to reach 5.\")\n",
    "    # Manually add more features to ensure we have 5 (e.g., using domain knowledge or more features from df)\n",
    "    additional_features = ['balance', 'age', 'pdays']  # Example, add more features if necessary\n",
    "    high_corr_features += additional_features[:5 - len(high_corr_features)]\n",
    "\n",
    "# Now that we have at least 5 features, apply PCA\n",
    "if len(high_corr_features) >= 5:\n",
    "    # Feature Extraction using PCA (reduce to 5 features)\n",
    "    pca = PCA(n_components=5)\n",
    "    df_pca = pca.fit_transform(df[high_corr_features])\n",
    "\n",
    "    # Convert PCA output to DataFrame\n",
    "    df_pca = pd.DataFrame(df_pca, columns=[f'PC{i+1}' for i in range(5)])\n",
    "\n",
    "    # Display the reduced features using pandas\n",
    "    print(df_pca.head())  # Display the PCA features in the console\n",
    "else:\n",
    "    print(\"Not enough features for PCA. Feature selection might need adjustment.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['age', 'marital', 'education', 'default', 'balance', 'housing', 'loan',\n",
      "       'contact', 'day', 'month', 'duration', 'campaign', 'pdays', 'previous',\n",
      "       'poutcome', 'deposit', 'education_encoded', 'job_blue-collar',\n",
      "       'job_entrepreneur', 'job_housemaid', 'job_management', 'job_retired',\n",
      "       'job_self-employed', 'job_services', 'job_student', 'job_technician',\n",
      "       'job_unemployed', 'job_unknown', 'marital_encoded', 'age_binned',\n",
      "       'balance_scaled', 'duration_scaled', 'campaign_scaled',\n",
      "       'deposit_encoded'],\n",
      "      dtype='object')\n",
      "Train shape: (7813, 33), Validation shape: (1674, 33), Test shape: (1675, 33)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Check the column names in the dataset to ensure 'deposit' is the target column\n",
    "print(df.columns)\n",
    "\n",
    "# Update the target column name if necessary\n",
    "X = df.drop(columns=['deposit'])  # Replace 'deposit' with the correct target column name\n",
    "y = df['deposit']  # Use the correct target column name here\n",
    "\n",
    "# Stratify ensures that the class distribution in the target column is preserved\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, stratify=y)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, stratify=y_temp)\n",
    "\n",
    "# Display the shape of each split\n",
    "print(f\"Train shape: {X_train.shape}, Validation shape: {X_val.shape}, Test shape: {X_test.shape}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
